import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
import cv2
import numpy as np
import pandas as pd
import stellargraph as sg
import scipy.sparse as sp
from gensim.models.doc2vec import Doc2Vec
from sklearn.preprocessing import LabelBinarizer
np.random.seed(10)

edge_type = {
    'IS_AST_PARENT': 1,
    'IS_CLASS_OF': 2,
    'FLOWS_TO': 3,
    'DEF': 4,
    'USE': 5,
    'REACHES': 6,
    'CONTROLS': 7,
    'DECLARES': 8,
    'DOM': 9,
    'POST_DOM': 10,
    'IS_FUNCTION_OF_AST': 11,
    'IS_FUNCTION_OF_CFG': 12,
    '' : 0
}

node_type = {
    'AndExpression': 1, 'Sizeof': 2, 'Identifier': 3, 'ForInit': 4, 'ReturnStatement': 5, 'SizeofOperand': 6,
    'InclusiveOrExpression': 7, 'PtrMemberAccess': 8, 'AssignmentExpression': 9, 'ParameterList': 10,
    'IdentifierDeclType': 11, 'SizeofExpression': 12, 'SwitchStatement': 13, 'IncDec': 14, 'Function': 15,
    'BitAndExpression': 16, 'UnaryExpression': 17, 'DoStatement': 18, 'GotoStatement': 19, 'Callee': 20,
    'OrExpression': 21, 'ShiftExpression': 22, 'Decl': 23, 'CFGErrorNode': 24, 'WhileStatement': 25,
    'InfiniteForNode': 26, 'RelationalExpression': 27, 'CFGExitNode': 28, 'Condition': 29, 'BreakStatement': 30,
    'CompoundStatement': 31, 'UnaryOperator': 32, 'CallExpression': 33, 'CastExpression': 34,
    'ConditionalExpression': 35, 'ArrayIndexing': 36, 'PostIncDecOperationExpression': 37, 'Label': 38,
    'ArgumentList': 39, 'EqualityExpression': 40, 'ReturnType': 41, 'Parameter': 42, 'Argument': 43, 'Symbol': 44,
    'ParameterType': 45, 'Statement': 46, 'AdditiveExpression': 47, 'PrimaryExpression': 48, 'DeclStmt': 49,
    'CastTarget': 50, 'IdentifierDeclStatement': 51, 'IdentifierDecl': 52, 'CFGEntryNode': 53, 'TryStatement': 54,
    'Expression': 55, 'ExclusiveOrExpression': 56, 'ClassDef': 57, 'File': 58, 'UnaryOperationExpression': 59,
    'ClassDefStatement': 60, 'FunctionDef': 61, 'IfStatement': 62, 'MultiplicativeExpression': 63,
    'ContinueStatement': 64, 'MemberAccess': 65, 'ExpressionStatement': 66, 'ForStatement': 67, 'InitializerList': 68,
    'ElseStatement': 69
}

class ProcessData:
    def __init__(self) -> None:
        self.n_class = 2
        self.n_node_max = 112
        self.n_node_feature = 69+64+1
        self.n_edge_type = 2 + self.n_node_feature + 12
        self.model_path = "./weights/d2v_model.model"

        self.load_model()
        self.load_encoder()

    def load_model(self):
        print(50 * "=")
        print("Load embedding model")
        self.model = Doc2Vec.load(self.model_path)

    def load_encoder(self):
        print(50 * "*")
        print("Load graph type encoder")
        self.edge_encoder = LabelBinarizer()
        self.edge_encoder.fit(list(edge_type.keys()))

        self.encoder = LabelBinarizer()
        self.encoder.fit(list(node_type.keys()))

    def handle_edges(self, path, node_mapper):
        edges_data = pd.read_csv(path + "/edges.csv", sep = "\t")[["start", "end", "type"]]
        temp = pd.DataFrame(self.edge_encoder.transform(edges_data['type']))
        edges_data = pd.concat([edges_data, temp], axis=1).drop(['type'], axis=1)
        edges_data = edges_data.groupby(["start", "end"]).sum().reset_index(level=["start", "end"])
        edges_data = edges_data.sort_values(["start"])
        edges_data.start = edges_data.start.map(node_mapper)
        edges_data.end = edges_data.end.map(node_mapper)
        return edges_data.astype(np.float64) 

    def get_vector(self, cell_value, model, path):
        try :
            tokens = str(cell_value).strip().split(" ")
            return model.infer_vector(doc_words=tokens, epochs=100, alpha=0.025).tolist()
        except Exception as e:
            print(50*"*")
            print("path error: ", path)
            print(50*"*")
            raise e

    def handle_nodes(self, path):
        nodes_data = pd.read_csv(path + "/nodes.csv", sep = "\t")
        nodes_data = nodes_data[["key", "type", "code", "isCFGNode"]]
        temp = pd.DataFrame(self.encoder.transform(nodes_data['type']))
        nodes_data = pd.concat([nodes_data, temp], axis=1).drop(['type'], axis=1)
        # isCFGNode
        nodes_data.isCFGNode = nodes_data.isCFGNode.astype(str).apply(lambda x: 1 if x == "True" else 0)
        nodes_data.at[0, "code"] = nodes_data.code.iloc[0].split('/')[0]
        # handle code
        vectors = [self.get_vector(c, self.model, path) for c in nodes_data.code.tolist() ]
        column_names = ["v_"+str(dim) for dim in range(self.model.vector_size)]
        df_vector = pd.DataFrame(vectors, columns=column_names)
        nodes_data = pd.concat([nodes_data,df_vector],  axis = 1)
        # key
        node_mapper = dict(zip(nodes_data.key, nodes_data.index))
        nodes_data.key = nodes_data.index
        
        return nodes_data.drop('code', axis = 1).astype(np.float64), node_mapper

    def get_node_features(self, node_data, edge_data):
        # Read in edges
        # renaming for StellarGraph compatibility
        edges = edge_data[['start', 'end']]
        edges.columns = ['source', 'target']

        # Get nodes and features
        features = node_data.drop("key", axis=1).to_numpy()
        node_features = pd.DataFrame(
            features, index=node_data['key'].astype('int'))

        # Init Graph
        G = sg.StellarGraph(nodes=node_features, edges=edges)

        # Get the adjacency matrix
        A = G.to_adjacency_matrix(weighted=False)
        # Add self-connections
        A_t = A + sp.diags(np.ones(A.shape[0]) - A.diagonal())
        # Degree matrix to the power of -1/2
        D_t = sp.diags(np.power(np.array(A.sum(1)), -0.5).flatten(), 0)
        # Normalise the Adjacency matrix
        adjacency = A.dot(D_t).transpose().dot(D_t).todense()

        features = cv2.resize(features, (self.n_node_feature, self.n_node_max))
        adjacency = cv2.resize(adjacency, (self.n_node_max, self.n_node_max))

        return features, adjacency

    # Vector có hướng AB được xác định bằng = 2 đỉnh (A, B) 
    #   concat (tọa độ điểm B - tọa độ điểm A) concat (vector one-hot của loại cạnh)
    def get_edge_features(self, node_data, edge_data):
        img = []
        data = edge_data.drop(["start", "end"], axis=1).to_numpy()
        max_node_num = edge_data[["start", "end"]].max(axis=1).max(axis=0)
        for index, row in edge_data[["start", "end"]].astype(np.int32).iterrows():
            start, end = row["start"], row["end"]

            start_node = node_data[node_data.key == start].drop(
                "key", axis=1).to_numpy().reshape(self.n_node_feature, )
            end_node = node_data[node_data.key == end].drop(
                "key", axis=1).to_numpy().reshape(self.n_node_feature, )
            directional_vector = end_node - start_node

            img.append(np.concatenate(
                [[start / max_node_num, end / max_node_num], directional_vector, data[index]]))

        img = np.array(img)
        img = cv2.resize(img, (self.n_node_max, self.n_node_max))
        return img.reshape((self.n_node_max, self.n_node_max, 1))


    def handle_cpg(self, path):
        print(50 * '-')
        print("Start process cpg graph data")
        df_nodes, node_mapper = self.handle_nodes(path)
        df_edges = self.handle_edges(path, node_mapper)

        if df_nodes.empty or df_edges.empty :
            raise "Error when handle cpg"

        try:
            node_features, node_adjacency = self.get_node_features(df_nodes, df_edges)
            edge_features = self.get_edge_features(df_nodes, df_edges)
        except Exception as e:
            print(e)
            raise e

        return [np.array([edge_features]), np.array([node_features]), np.array([node_adjacency])]

if __name__ == "__main__":
    process_data = ProcessData()
    data = process_data.handle_cpg("parsed/tmp/source_no_0.c")
    print("handle cpg done")
    print(data)

